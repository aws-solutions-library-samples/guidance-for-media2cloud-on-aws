// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
// SPDX-License-Identifier: Apache-2.0

const COPYRIGHT = 'copyright &copy; 2024';
// avoid fortify false positive
const FIELD_PWD = ['P', 'a', 's', 's', 'w', 'o', 'r', 'd'].join('');

export default class Localization {
  static get isoCode() {
    return 'en-US';
  }

  static get Copyright() {
    return COPYRIGHT;
  }

  static get Messages() {
    return Localization.Languages[Localization.isoCode].Messages;
  }

  static get Tooltips() {
    return Localization.Languages[Localization.isoCode].Tooltips;
  }

  static get Buttons() {
    return Localization.Languages[Localization.isoCode].Buttons;
  }

  static get Alerts() {
    return Localization.Languages[Localization.isoCode].Alerts;
  }

  static get Statuses() {
    return Localization.Languages[Localization.isoCode].Statuses;
  }

  static get RegularExpressions() {
    return {
      // letter, number, punctunation, currency, and space
      // \p{scx=Cyrl} - Cyrillic or Hindi
      CharacterSetForSearch: '[\\p{L}\\p{P}\\p{N}\\p{Sc}\\s]+',
      CharacterSet128: '^[\\p{L}\\p{P}\\p{N}\\p{Sc}\\s_.\\-]{0,128}$',
      CharacterSet255: '^[\\p{L}\\p{P}\\p{N}\\p{Sc}\\s_.\\-]{0,255}$',
      // Username
      Username: '[a-zA-Z0-9._+\\-]{1,128}',
      // (L) Letter, (Mn) accents, (Pd) hyphens, space, underscore, dot, single quote, dash
      UnicodeUsername: '^[\\p{L}\\p{Mn}\\p{Pd}\\s_.\'\\-]{1,128}$',
    };
  }

  static get Languages() {
    return {
      'en-US': {
        Messages: {
          /* signin flow */
          Title: 'Media2Cloud Demo Portal <span style="font-size:0.85rem">by AWS Industry Specialist Team</span>',
          PwdRequirement: `${FIELD_PWD} must be at least <abbr title="eight characters">eight</abbr> characters long and contain <abbr title="one uppercase character">one</abbr> uppercase, <abbr title="one lowercase character">one</abbr> lowercase, <abbr title="one numeric character">one</abbr> number, and <abbr title="one special character">one</abbr> special character.`,
          ResetSendCode: `Please enter the username and press <strong>Send code</strong>. You should receive a 6-digits code in mail in a few minutes. You will need the code to reset the ${FIELD_PWD}.`,
          ResetPwd: `Please enter the verification code that has sent to your email address and your new ${FIELD_PWD}.`,
          /* main view */
          SolutionName: 'Guidance for Media2Cloud on AWS',
          /* about tab panel */
          AboutTab: 'About',
          Mission: 'Guidance for Media2Cloud on AWS is designed to help customers to blah...',
          Design: 'Architecture Design goes here...',
          Team: 'Team member goes here...',
          /* stats tab panel */
          StatsTab: 'Stats',
          /* face collection tab panel */
          FaceCollectionTab: 'FaceCollection',
          /* setting tab panel */
          SettingsTab: 'Settings',
          SettingsDesc: 'This setting page allows you to configure and fine tune AI/ML settings for each of the Amazon AI services. (Admin privileges required)',
          DatastoreFeature: 'Local Data Store (IndexedDB)',
          DatastoreFeatureDesc: 'Media2Cloud uses <a href="https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API" target="_blank">IndexedDB</a> to cache thumbnail images, datasets, and other settings locally. Click <strong/>Clean up data store</strong> to delete the local data.',
          TranscodeFeatures: 'AWS Elemental MediaConvert Settings',
          RekognitionFeatures: 'Amazon Rekognition Settings',
          RekognitionFeaturesDesc: '<a href="https://aws.amazon.com/rekognition" target="_blank">Amazon Rekognition</a> allows you to detect celebrities, faces, labels, objects or create your own <a href="https://docs.aws.amazon.com/rekognition/latest/dg/collections.html" target="_blank">Face Collection</a> to match faces in your collection.',
          ComprehendFeatures: 'Amazon Comprehend Settings',
          ComprehendFeaturesDesc: '<a href="https://aws.amazon.com/comprehend/" target="_blank">Amazon Comprehend</a> allows you to extract keyphrases, entities, sentiments, and classification. You can also train your <a href="https://docs.aws.amazon.com/comprehend/latest/dg/custom-entity-recognition.html" target="_blank">Custom Entity Recognizer</a> to identify custom entities for your business needs. Check out this blog post, <a href="https://aws.amazon.com/blogs/machine-learning/build-a-custom-entity-recognizer-using-amazon-comprehend/" target="_blank">Build a custom entity recognizer using Amazon Comprehend</a>.',
          TranscribeFeatures: 'Amazon Transcribe Settings',
          TranscribeFeaturesDesc: '<a href="https://aws.amazon.com/transcribe/" target="_blank">Amazon Transcribe</a> is a automatic speech recognition (ASR) service. Media2Cloud extracts audio stream from your asset and autmatically create subtitle track using <a href="https://aws.amazon.com/blogs/aws/amazon-transcribe-now-supports-automatic-language-identification/" target="_blank">Amazon Transcribe Automatic Language Identification feature</a>. You can also train a custom language model to improve the ASR result. Check out this blog post, <a href="https://aws.amazon.com/blogs/machine-learning/building-custom-language-models-to-supercharge-speech-to-text-performance-for-amazon-transcribe/" target="_blank">Building custom language models to supercharge speech-to-text performance for Amazon Transcribe</a>. (Note that Custom Language Model currently supports English only.)',
          TextractFeatures: 'Amazon Textract Settings',
          TextractFeaturesDesc: '<a href="https://aws.amazon.com/textract/" target="_blank">Amazon Textract</a> is an optical character recognition (OCR) service that allows you to extract text and relationship of a document such as PDF file.',
          AIMLSetting: 'AI/ML Settings',
          AdvanceFeatures: 'Advanced Features',
          /* collection tab panel */
          CollectionTab: 'Collection',
          /* upload tab panel */
          UploadTab: 'Upload',
          ReviewAnalysisSettings: 'Carefully review the following AI/ML settings that are used to analyze the contents.',
          Enabled: 'Enabled',
          Disabled: 'Disabled',
          NotSet: 'Not set',
          /* search component */
          Search: 'Search',
          Submit: 'Submit',
          SearchDesc: 'The search feature is powered by <a href="https://aws.amazon.com/opensearch-service/features/serverless/" target="_blank">Amazon OpenSearch Serverless</a>, a managed service that scales to support petabyte storage without configuring or managing clusters. It now supports <strong>complex search query</strong> where you can use keywords such as <code>and</code>, <code>or</code>, <code>not</code> logical operators, <code>parenthesis</code> to group terms, <code>quotation</code> for exact phrase match, and <code>wildcard</code> search. See examples and syntax below.',
          SearchQueryFailed: 'Fail to query the search results',
          ExactMatch: 'Exact match',
          PageSize10: '10 results per page',
          PageSize30: '30 results per page',
          PageSize50: '50 results per page',
          SearchResultDesc: 'Search results',
          Category: 'Category',
          SearchExampleSyntax: 'Search examples and syntax',
          SearchExampleSyntaxDesc: 'The Amazon OpenSearch Service (search engine) can support complex search. For instance, you can search for multiple people who are present in the same video such as <code>Andy Jassy</code> and <code>Werner Vogels</code>. You can search for videos where <code>Andy Jassy</code> has said <code>"There is no compression algorithm for experience."</code>. Or, you can search for <code>Jeff Bezos</code> in video where <code>Blue Origins rocket launch</code>. Also note that, the search query is <strong>case insensitive</strong> that implies searching <code>Andy Jassy</code> and <code>andy jassy</code> returns the same results.  Let\'s take a look at a few search examples below.',
          SearchExample1: 'Example 1: Simple search with a name',
          SearchExample1Desc: 'Search: <code>Andy Jassy</code><br/>The results may return <code>Andy Jassy</code>, <code>Peter Jassy</code>, <code>Andy Jo</code>, and so forth. This is because the search query searches for any name that contains either <code>Andy</code> or <code>Jassy</code>. Obviously, some names are not really what you are looking for. The next example shows you how to perform an exact match search.',
          SearchExample2: 'Example 2: Exact match search of a name',
          SearchExample2Desc: 'Search: <code>"Andy Jassy"</code><br/>Instead of typing <code>Andy Jassy</code>, use the double quotation mark, <code>"Andy Jassy"</code>. When the search query is quoted, the search engine performs a search of the entire phrase instead of individual word of the phrase. This can be very useful when you are searching a phrase in the transcription. For instance, searching Andy Jassy\'s famous quote, <code>"no compression algorithm for experience."</code>',
          SearchExample3: 'Example 3: Search for multiple names and phrases',
          SearchExample3Desc: 'Search: <code>"Andy Jassy" AND "no compression algorithm for experience."</code><br/>You can use <code>AND</code>, <code>OR</code>, and/or <code>NOT</code> keywords to perform complex search. The search query above returns videos where <span class="text-success">Andy Jassy</span> says <span class="text-success">"no compression algorithm for experience."</span>.',
          SearchExample4: 'Example 4: Complex search with grouping',
          SearchExample4Desc: 'Search: <code>(("Andy Jassy" OR "Werner Vogels") NOT "AWS Summit")</code><br/>You can use parenthesis, <code>(</code> and <code>)</code> to build a complex search query. In this example, searching <code>(("Andy Jassy" OR "Werner Vogels") NOT "AWS Summit")</code> returns videos where both <span class="text-success">Andy Jassy</span> and <span class="text-success">Werner Vogels</span> are present but NOT in an <span class="text-success">AWS Summit</span> event.',
          SearchExample5: 'Example 5: Wildcard search??',
          SearchExample5Desc: 'Search: <code>(Werner AND Vog*) OR (Andy AND Jas??)</code><br/>Yes, you can do wildcard search, an asterisk <code>*</code> or a question mark, <code>?</code> where <code>*</code> matches multiple characters and <code>?</code> matches one character. <span class="font-weight-bold">It is important to note that <code>*</code> and <code>?</code> inside a double quotation (a phrase) is literal and will not match multiple characters.</span> In this example, <code>(Werner AND Vog*) OR (Andy AND Jas??)</code> will match <span class="text-success">Werner Vog<strong>els</strong></span> or <span class="text-success">Andy Jas<strong>sy</strong></span>',
          /* ai options */
          Transcript: 'Transcript',
          KnownFaces: 'Known faces',
          Keyphrases: 'Key phrases',
          Entities: 'Entities',
          VisualText: 'Visual text',
          ContentAttributes: 'Content attributes',
          TranscriptPhrasesEntities: 'Transcript, Phrases, & Entities',
          LabelsModeration: 'Labels & Moderation',
          /* content sub-tab */
          ContentTab: 'Content',
          /* processing tab */
          VideoTab: 'Video',
          PhotoTab: 'Photo',
          PodcastTab: 'Podcast',
          DocumentTab: 'Document',
          SearchTab: 'Search',
          GroupTab: 'Group',
          NoMediaPresent: 'You don\'t have any <abbr title="media">{{MEDIATYPE}}</abbr> files in your collection. Navigate to <abbr title="upload">{{UPLOADTAB}} Tab</abbr> to start adding files.',
          MediaInProcess: '<p><strong>{{BASENAME}}</strong> media is still in process. Please navigate to <strong>{{PROCESSINGTAB}} Tab</strong> to check the progress.</p>',
          MediaError: '<p><strong>{{BASENAME}}</strong> media has failed to process. Please navigate to <strong>{{PROCESSINGTAB}} Tab</strong> to see more details.</p>',
          RemoveMedia: '<p/>Removing <strong/>{{BASENAME}}</strong> will <u>delete</u> all proxies, metadata, and records from the collection.</p><p>Would you like to proceed?</p>',
          ProcessingTab: 'Processing',
          ProcessingDesc: 'List of processing jobs',
          ProcessingError: 'Fail to process <abbr title="basename">{{BASENAME}}</abbr>. Navigate to <abbr title="processing">{{PROCESSINGTAB}} Tab</abbr> to check the details.',
          ErrorDesc: 'List of recent error jobs',
          Name: 'Name',
          Uuid: 'Unique Id',
          Status: 'Current status',
          OverallStatus: 'Overall status',
          /* dropzone */
          DropzoneDesc: 'Drag and drop file(s) to the \'drop area\' or click on \'Browse files\' to select file(s) to start the process. You can drop multiple files or folders. (Note: Folder is supported in Chrome, Firefox, and Edge browsers.)',
          AttributeDesc: 'Associate additional information to the files. The information will be indexed to <a href="https://aws.amazon.com/elasticsearch-service/" target="_blank">Amazon Elasticsearch service</a> and be made available through the search feature.',
          AnalysisDesc: 'Media2Cloud uses various AWS AI services to analyze video, images, audio, and documents. The analysis includes detecting celebrities, faces, labels, moderations, key phrases, entities, sentiments, and transcription. To learn more about AWS AI services, please visit <a href="https://aws.amazon.com/rekognition/" target="_blank">Amazon Rekognition</a>, <a href="https://aws.amazon.com/transcribe/" target="_blank">Amazon Transcribe</a>, and <a href="https://aws.amazon.com/comprehend/" target="_blank">Amazon Comprehend</a>.',
          FinalizeUploadDesc: 'This final upload process assigns an unique ID (uuid) to each file, checks for collision, computes a MD5 checksum of the file, and uses <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html" target="_blank">multipart upload</a> to transfer the file to your Amazon S3 Bucket, {{BUCKET}}. Please confirm the final list below and click on \'Start now\' to start the process.',
          DropFileHere: 'Drop file(s) here to start',
          FileToBeProcessed: 'File(s) to be processed:',
          /* attribute component */
          GroupName: 'Specify group name',
          GroupDesc: 'Specify a group name to tie all the files together. You can then search the files by group later on. The group name should only contain alphanumeric, dash, and underscore characters. Leave it blank if you don\'t want to group them.',
          AttrDesc: 'Attach additional attributes such as author, synopsis, or genre to the files. The attribute is a set of key-value pairs. Key can contain alphanumeric, dash and underscore characters. Value can contain alphanumeric, dash, underscore, comma, period, or percent sign characters. Use encodeURIComponent to encode the value if it contains other characters.',
          /* analysis component */
          FramebasedDesc: 'Frame based analysis uses Amazon Rekognition <code>Image</code> APIs instead of Amazon Rekognition <code>Video</code> APIs to analyze video files. Detections include celebrities, faces, labels, moderations, and texts. (Note: segment and person pathing detections continue to use Amazon Rekognition Video APIs.)<br><span class="text-success">New feature:</span> <code>Use dynamic frame (Hamming distance)</code> option uses perceptual hash (hamming distance) to pick frames to analyze. In average, it is roughly equivalent to <code>1 frame every 4 seconds</code> to <code>1 frame every 6 seconds</code>.',
          Framebased: 'Frame based analysis',
          FaceCollectionId: 'Face collection',
          CustomLabelModels: 'Custom label model(s)',
          FrameCaptureMode: 'Frame based analysis',
          FrameCaptureModeNone: 'Disable frame analysis',
          FrameCaptureModeDynamic: 'Use dynamic frame (Hamming distance)',
          FrameCaptureMode1FPS: '1 frame per second',
          FrameCaptureMode2FPS: '2 frames per second',
          FrameCaptureMode3FPS: '3 frames per second',
          FrameCaptureMode4FPS: '4 frames per second',
          FrameCaptureMode5FPS: '5 frames per second',
          FrameCaptureMode10FPS: '10 frames per second',
          FrameCaptureMode12FPS: '12 frames per second',
          FrameCaptureMode15FPS: '15 frames per second',
          FrameCaptureModeAllFrames: 'Every frame',
          FrameCaptureModeEveryOtherFrame: 'Every other frame',
          FrameCaptureMode1FramePer2Seconds: '1 frame every 2 seconds',
          FrameCaptureMode1FramePer5Seconds: '1 frame every 5 seconds',
          FrameCaptureMode1FramePer10Seconds: '1 frame every 10 seconds',
          FrameCaptureMode1FramePer30Seconds: '1 frame every 30 seconds',
          FrameCaptureMode1FramePer1Minute: '1 frame every 1 minute',
          FrameCaptureMode1FramePer2Minutes: '1 frame every 2 minutes',
          FrameCaptureMode1FramePer5Minutes: '1 frame every 5 minutes',
          DynamicFrameName: 'Dynamic frame results',
          DynamicFrameDesc: '<code>{{EXTRACTED}}</code> frames extracted from the video. Actual <code>{{ANALYZED}}</code> frames used to analyze. Total <code>{{PERCENTAGE}}%</code> of Amazon Rekognition Image API calls saved.',
          AutoFaceIndexerStatsName: 'Face indexing results',
          AutoFaceIndexerStatsDesc: 'Total of <code>{{FACES_INDEXED}}</code> new faces added to the collection with a total of <code>{{API_COUNT}}</code> Amazon Rekognition IndexFaces API and a total of <code>{{FACE_API_COUNT}}</code> Amazon Rekognition DetectFaces API invoked.',
          ApiCountName: 'API invocations',
          ApiCountDesc: 'Total of <code>{{API_COUNT}}</code> Amazon Rekognition API are invoked.',
          TextROI: 'Text regions of interest',
          LanguageCode: 'Language code',
          CustomLanguageModel: 'Custom Language Model',
          CustomVocabulary: 'Custom vocabulary',
          CustomEntityRecognizer: 'Custom Entity Recognizer',
          TextRegionOfInterest: 'Region of Interest for Amazon Rekognition Text Detection',
          SelectModel: 'Select a model...',
          SelectModels: 'Select model(s)...',
          SelectFrameCaptureMode: 'Select mode...',
          SelectLanguageCode: 'Auto detect language...',
          SelectCollection: 'Disable facematch (SearchFacesByImage API)',
          MinConfidence: 'Min. confidence',
          Celeb: 'Celebrity detection',
          Label: 'Label detection',
          Face: 'Face detection',
          Facematch: 'Face match detection',
          Person: 'Person detection',
          Moderation: 'Moderation detection',
          Text: 'Text detection',
          Entity: 'Entity detection',
          Keyphrase: 'Keyphrase detection',
          Sentiment: 'Sentiment analysis',
          Topic: 'Topic analysis',
          Document: 'Document analysis',
          Segment: 'Shot segment detection',
          CustomlabelDesc: 'With <a href="https://aws.amazon.com/rekognition/custom-labels-features/" target="_blank">Amazon Rekognition Custom Labels Feature</a>, you can quickly train a computer vision (CV) model such as image classification or object detection model to identify objects or classes based on your business needs. Select up to <code>{{MAX_CUSTOMALBELMODELS}} models</code>. Check out this GitHub sample solution, <a href="https://github.com/aws-samples/amazon-rekognition-custom-brand-detection" target="_blank">Building brand (custom object) detection demo</a>.',
          Customlabel: 'Custom label detection',
          ComprehendInCertainLanguage: '** Comprehend features may not be available in certain languages',
          ImageProperty: 'Image property detection',
          Scene: 'Scene detection',
          SceneDesc: '<span class="text-success">New feature:</span> Scene detection uses AI/ML metadata to group shots into scenes. The feature uses <code>Frame Based analysis</code>, <code>Amazon Rekognition Shot Segment</code>, and <code>open source image embeddings model</code>.',
          SceneListTitle: 'View a list of detected scenes ({{SCENES}}):',
          SceneDetailTitle: 'Scene description',
          SceneDetailDesc: '<strong>Scene #{{SCENE_NO}}</strong> starts at <code/>{{SMPTE_START}}</code> and ends at <code/>{{SMPTE_END}}</code>, elapsed <code/>{{DURATION}}</code> seconds. It contains {{SHOTS}} shots from Shot <code/>#{{SHOT_START}}</code> to Shot <code/>#{{SHOT_END}}</code>.',
          SceneEnhanceWithTranscript: 'Enhancing scenes w/ transcript',
          SceneEnhanceWithLLM: 'Scene description & taxonomies (GenAI)',
          MinFrameSimilarity: 'Min. frame similarity',
          MaxTimeDistance: 'Frame proximity range (min)',
          AdBreak: 'Ad Break detection',
          AdBreakInterval: 'Break interval (mins)',
          AdBreakOffset: 'Break offset (mins)',
          PauseWeight: 'Speech pause weight',
          QuietnessWeight: 'Audio quietness weight',
          ContextualWeight: 'Label contextual weight',
          AdBreakDesc: '<span class="text-success">New feature:</span> Ad Break detection uses AI/ML metadata to estimate potential slots within the content where are suitable for inserting Ad minimizing the impact or disruption of the user viewing experience. The feature requires <code>Scene detection</code>, <code>Frame Based analysis</code>, <code>Amazon Rekognition Label Detection</code>, <code>Amazon Rekognition Shot Segment</code>, <code>Amazon Transcribe</code>, and <code>AWS Elemental MediaConvert Audio normalization (Loudness logging)</code> enabled.',
          AdBreakDetailTitle: 'Ad break description',
          AdBreakDetailDesc: '<strong>Ad break #{{BREAK_NO}}</strong> is detected at <code/>{{SMPTE_TIMESTAMP}}</code>, right <strong>{{BREAK_TYPE}}</strong> Scene #{{SCENE_NO}}. The ad break is recommended based on the momentary loudness of <code>{{MOMENTARY}} LUFS</code>, the speech pause duration of <code>{{PAUSE_DURATION}}s</code> around the ad break, and the contextual metadata distance of <code>{{CONTEXTUAL_DISTANCE}}</code> before and after the ad break.',
          AutoFaceIndexer: 'Auto Face Indexer',
          AutoFaceIndexerDesc: '<span class="text-success">New feature:</span> Auto Face Indexer feature actively indexes unrecognized faces to a Face Collection. Once the unrecognized faces are tagged, the faces would then be identified in contents without re-running the analysis.',
          MinFaceWidth: 'Face Width min. pixels',
          MinFaceHeight: 'Face Height min. pixels',
          MinFaceBrightness: 'Brightness min. value',
          MinFaceSharpness: 'Sharpness min. value',
          MaxPosePitch: 'Pose Pitch max. threshold',
          MaxPoseRoll: 'Pose Roll max. threshold',
          MaxPoseYaw: 'Pose Yaw max. threshold',
          MinCelebConfidence: 'Celebrity min. confidence',
          OccludedFaceFiltering: 'Filter occluded faces',
          ZeroshotLabel: 'Zero-Shot Label',
          ZeroshotLabelDesc: '<span class="text-success">New feature:</span> Zero-Shot Label feature support both object detection and image classification without training a ML model. You can define your text query such as <code>dress, hat, skirt, blazer, pant</code> or upload images of the objects you would like to identify.',
          Shoppable: 'Shoppable experience',
          ShoppableDesc: '<span class="text-success">New feature:</span> Shoppable metadata detection uses machine learning models to identify apparel items in the content. It then finds similar items in your product catalog stored in Amazon OpenSearch with KNN, a <code>vector store</code>. This feature is disabled by default. Contact your AWS sales representative if you would like to try out this feature.',
          Toxicity: 'Toxicity detection',
          ToxicityDesc: '<span class="text-success">New feature:</span> Amazon Transcribe now supports Toxicity detection on speech. It requires <code>language code</code> set to en-US, <code>custom vocabulary</code> and <code>custom language model</code> disabled.',
          AnalyseConversation: 'Analyse conversation (GenAI)',
          BlackFrameDesc: '<span class="text-success">Black frame setting:</span> a filter that allows you to control the black frame detection by specifying the black levels and pixel coverage of black pixels in a frame. Applicable to Amazon Rekognition Segment API. Refer to <a href="https://docs.aws.amazon.com/rekognition/latest/APIReference/API_StartTechnicalCueDetectionFilter.html" target="_blank">Amazon Rekognition documentation</a>.',
          BlackFramePixelThreshold: 'Max. pixel threshold',
          BlackFrameCoveragePercentage: 'Min. coverage %',
          EnableTechnicalCue: 'Enable technical cues (ie., ColorBars, EndCredits)',
          InputCropDesc: '<span class="text-success">Input cropping setting:</span> a filter that allows you to crop the input video to remove potential noises introduced by Vertical Blanking Interval (VBI) scan lines.',
          InputCropX: 'X offset (pixels)',
          InputCropY: 'Y offset (pixels)',
          InputCropKeepAR: 'Maintain aspect ratio',
          /* finalize component */
          Summary: 'Summary',
          Source: 'Source',
          FileName: 'Name',
          FileSize: 'Size',
          FileType: 'Type',
          LastModified: 'Last modified',
          Destination: 'Destination',
          Bucket: 'Bucket',
          Key: 'Key',
          Attributes: 'Attributes',
          UploadStatus: 'Upload status',
          ValidateUuid: 'Validate uuid',
          ComputeChecksum: 'Compute checksum',
          UploadS3: 'Upload to S3',
          /* content tab */
          VideoCategory: 'Video category',
          PhotoCategory: 'Photo category',
          PodcastCategory: 'Podcast category',
          DocumentCategory: 'Document category',
          GroupCategory: 'Group category',
          CelebrityCategory: 'Celebrity category',
          LoadMore: 'Load more...',
          NoMoreData: 'No more data...',
          /* preview */
          NoData: 'No relevant data...',
          /** technical */
          GeneralGroup: 'General',
          ProxyGroup: 'Proxies',
          MediaInfoGroup: 'MediaInfo',
          EXIFGroup: 'EXIF',
          BasicGroup: 'Basic',
          GPSGroup: 'GPS',
          PDFGroup: 'PDF Info',
          OthersGroup: 'Others',
          TechnicalGroup: 'Technical',
          SourceTab: 'Source',
          ProxiesTab: 'Proxies',
          MediainfoTab: 'Mediainfo',
          ImageinfoTab: 'EXIF Info',
          Basic: 'Basic',
          GPS: 'GPS',
          ShowMap: 'Show location',
          More: 'More...',
          DocinfoTab: 'Docinfo',
          /** analysis */
          AnalysisGroup: 'Analysis',
          StatisticsTab: 'Statistics',
          SearchResultTab: 'Search Results',
          ReAnalyzeTab: 'Re-Analyze',
          SummaryTab: 'Summary',
          WorkflowHistory: 'AWS Step Functions (workflow history)',
          Rekognition: 'Amazon Rekognition',
          Comprehend: 'Amazon Comprehend',
          Transcribe: 'Amazon Transcribe',
          Textract: 'Amazon Textract',
          Labels: 'Labels',
          DownloadJson: 'Download JSON',
          TranscribeTab: 'Transcribe',
          ImageCaptionTab: 'Captioning',
          CelebTab: 'Celebrity',
          LabelTab: 'Label',
          FaceMatchTab: 'Face Match',
          FaceTab: 'Face',
          PersonTab: 'Person',
          SegmentTab: 'Segment',
          TextTab: 'Text',
          ModerationTab: 'Moderation',
          KeyphraseTab: 'Keyphrase',
          EntityTab: 'Entity',
          SentimentTab: 'Sentiment',
          TopicTab: 'Topic',
          ClassificationTab: 'Classification',
          TextractTab: 'Textract',
          CustomLabelTab: 'Custom label',
          EnableAll: 'Enable all labels',
          ToggleAll: 'Toggle all labels',
          ToggleTextOverlay: 'Enable text overlay',
          TranscriptionJob: 'Transcription Job',
          SubtitleSwitch: 'Turn subtitle on/off',
          ShowTranscript: 'View the full transcript in <code>{{LANGUAGECODE}}</code>',
          DownloadEDLDesc: 'Media2Cloud converts AI/ML detection results to Edit Decision List (EDL) format that allows you to import the detection results as timelines into popular editing software.',
          ScatterGraphDesc: 'Toggle a legend to show or hide data points of the selected label. Click on individual data point to seek to the timestamp on the video to see the detection results.',
          SearchSpecificLabel: '(Search specific label)',
          FaceTagging: 'Tagging faces',
          FaceTaggingToolDesc: 'You got numbers of faces that have not been tagged. Click on the <code>{{FACE_TAGGING_TOOL}}</code> to name the unrecognized faces.',
          FaceTaggingInstruction: 'Left panel contains faces that have not been tagged. Right panel provides controls to name (or delete) face(s). To tag a face (or group of faces), hover to the face image and click on <code>Select</code> button. Provide a name, click on the <code>Lock</code> icon to confirm. To delete a face or faces, select the faces from the left panel and click on <code>Trash</code> icon to confirm. Repeat the steps to add (or delete) groups of faces. When you are ready, click on <code>Apply changes and done</code> button.',
          FaceTaggingShortInstruction: 'To tag face(s), provide a name in the <code>Name</code> field and click on the <code>Lock</code> icon. To remove faces from the collection, click on <code>Trash</code> icon.',
          ManageFaceTagging: 'Manage face(s) identified in this content',
          ToBeRemoved: 'To be removed',
          /* textract */
          Row: 'Row',
          Rows: 'Rows',
          Table: 'Table',
          Tables: 'Tables',
          KeyValueSets: 'Key Value Sets',
          Lines: 'Lines',
          Page: 'Page',
          /** tools */
          ToolsGroup: 'Tools',
          SnapshotTab: 'Snapshot',
          EnableSnapshot: 'Enable snapshot',
          DoneSnapshot: 'Done snapshot',
          CaptureImage: 'Capture image',
          SelectLabels: 'Select label(s)...',
          SelectNone: 'Deselect all',
          SelectAll: 'Select all',
          /* Stats */
          StatsDesc: 'Provide overall and categorized statistics of your collection.',
          OverallStats: 'Overall stats',
          TotalCount: 'Total number of media per category',
          TotalSize: 'Total sizes of media per category',
          WorkflowStatuses: 'Overview of workflow statuses',
          MostRecentStats: 'Most recently ingested media',
          Aggregations: 'Aggregations of AI/ML metadata',
          TopKnownFaces: 'Top known faces in library',
          TopLabels: 'Top labels in library',
          TopModerations: 'Top moderation labels in library',
          TopKeyphrases: 'Top keyphrases in library',
          TopEntities: 'Top entities in library',
          LongestFile: 'Longest duration in library',
          LargestFile: 'Largest filesize in library',
          /* FaceCollection */
          FaceCollectionDesc: 'Create, view and manage your Amazon Rekognition Face Collection(s).',
          AvailableFaceCollections: 'List of available face collection(s)',
          IndexedFacesInCollection: 'Faces indexed in <strong>{{FACECOLLECTION}}</strong> collection,',
          SelectFaceCollection: 'Select a face collection...',
          Alternatively: 'Alternatively,',
          ManagedByFaceIndexer: 'managed by <u>Auto Face Indexer</u>.',
          NotManagedByFaceIndexer: '<u>not</u> managed by <u>Auto Face Indexer</u>.',
          UploadIndexFaces: 'Use the <span class="text-success">Upload faces images</span> feature to upload images that contain the faces you would like to add to this collection. (The naming convention of the image is <strong>[Name].jpg</strong>. For instance, <strong>Werner Vogels.jpg</strong>. Each image should only contain one face that you want to add to the collection. JPEG and PNG image formats are supported.)',
          ImportFaceCollection: 'Use the <span class="text-success">Import collection</span> feature to bring this collection under <u>Auto Face Indexer</u> management.',
          ImportCollectionCompleted: 'Successfully imported <code>{{FACECOLLECTION}}</code> collection. Reloading the table...',
          ColumnFaceId: 'FaceId',
          ColumnExternalImageId: 'ExternalImageId',
          ColumnIndexedAt: 'IndexedAt',
          ColumnRelatedAssetId: 'RelatedAssetId',
          ColumnOnScreenTime: 'ScreenTime',
          ColumnRemove: 'Remove?',
          /* Snapshot */
          EnableSnapshotMode: 'Snapshot mode',
          /* UserManagementTab */
          UserManagementTab: 'User Management',
          UserManagementDesc: 'The page provides a simple way to manage users and control user accesses to the Media2Cloud web portal. The user directory is managed by <a href="https://aws.amazon.com/cognito/" target="_blank">Amazon Cognito User Pool</a>. (Administrator privilege required.) Alternatively, you can manage your user directory from <a href="{{CONSOLE_USERPOOL}}" target="_blank">Amazon Cognito User Pools Console</a>.',
          Username: 'Username',
          Email: 'Email',
          Group: 'Group',
          Permission: 'Permission',
          RemoveUser: 'Remove user?',
          GenerateUserToken: 'Generate token',
          PermissionViewer: 'Can view assets',
          PermissionCreator: 'Can view and ingest assets',
          PermissionAdmin: 'Full admin access',
          CurrentUsers: 'List of current user(s)',
          CreateNewUsers: 'Create new user(s)',
          CreateNewUsersDesc: 'To add a new user, click on <strong>{{ADD_EMAIL}}</strong> button, enter a valid <em>email address</em>, assign user to a <em>group</em>, and (optionally) specify an <em>username</em>. Repeat the process to add multiple users. When you are ready, click on <strong>{{CONFIRM_AND_ADD}}</strong> button to create the user(s).',
          /* Image caption */
          ImageCaptionDesc: 'Image caption and other information are generated by using Anthropic Claude 3 Haiku (or Sonnet) Text & Vision model managed by Amazon Bedrock',
          /* Knowledge Graph */
          KnowledgeGraphTab: 'Knowledge Graph',
          KnowledgeGraphTabDesc: 'Demonstrates a graph representation of the content and how it is related to other contents in your archive library',
          KGViewConnections: 'View search results\' connections (Note: the query could take a few seconds)',
          // GenAI
          GenAITab: 'GenAI',
          Bedrock: 'Foundation models on Amazon Bedrock',
          BedrockDesc: 'Make sure you have requested access to Bedrock\'s Foundation models. Go to AWS console, select Amazon Bedrock service. Under the Model access page, request access to the models.',
          AdjustParameters: 'Parameters to adjust the output:',
          Template: 'Template',
          Prompt: 'Prompt',
          Temperature: 'Temperature',
          TopK: 'Top-K',
          TopP: 'Top-P',
          MaxLength: 'MaxLength',
          OriginalTranscriptPlaceholder: '== Original transcript ==',
          ModelName: 'Model name',
          // AdBreak
          AdBreakTab: 'Ad Breaks',
          AdBreakTabDesc: 'Identify potential Ad break opportunities in the video. The detection combines numbers of metadata outputs generated by AWS AI/ML services to derive the likelihood (weight) of timestamps to insert advertisement without randomly cutting off on-going dialogues.',
          AdBreakGraphTitle: 'Graph view of the Ad breaks',
          AdBreakListTitle: 'List view of the Ad breaks',
          // Shoppable
          ShoppableTab: 'Shoppable Items',
          ShoppableTabDesc: 'Identify potential shoppable products in the video. This features uses <code>AWS AI/ML services</code> to identify apparels in the video, <code>Amazon OpenSearch Service</code> with K-NN plugin to map apparel items to product ID from <code>Amazon.com</code>, and a new, <code>invite only</code> service provided by <code>Amazon</code> to enable immersive purchasing for relevant products.',
          ShoppableListTitle: 'A list of frame images that contains shoppable items',
          ShoppableItemsDesc: 'Numbers of items ({{ITEMS}}) detected in the frame image. Hover to and click on the <code>green dots</code> to see similar products on amazon.com',
          ShoppableAmazonTitle: 'Shop similar products at Amazon.com',
          ShoppableMetadataTitle: 'Show shoppable metadata in JSON format',
        },
        Tooltips: {
          /* main view */
          VisitSolutionPage: 'Visit AWS Solutions Library',
          Logout: 'ready to logout?',
          RemoveMedia: 'Remove media from collection',
          /* analysis component */
          MinConfidence: 'Set the minimum confidence level for various Amazon Rekognition detection(s) to return the result set',
          FaceColection: 'Uses Amazon Rekognition Face Collection',
          CustomLabelModels: 'Uses Amazon Rekognition Custom Labels feature',
          FrameCaptureMode: 'Define frame interval to run Custom Labels detection',
          TextROI: 'Define the regions of interest to run Amazon Rekognition Text detection',
          LanguageCode: 'Specify language code to run Amazon Transcribe',
          CustomLanguageModel: 'Uses Amazon Transcribe Custom Language Model (English only)',
          CustomVocabulary: 'Uses Amazon Transcribe Custom Vocabulary',
          CustomEntityRecognizer: 'Uses Amazon Comprehend Custom Entity Recognizer',
          TextRegionOfInterest: 'Define region of interest for Amazon Rekognition Text Detection',
          Celeb: 'Uses Amazon Rekognition celebrity recognition detection',
          Label: 'Uses Amazon Rekognition label detection',
          Face: 'Uses Amazon Rekognition face detection',
          Facematch: 'Uses Amazon Rekognition face search to match indexed faces in your own face collection',
          Person: 'Uses Amazon Rekognition person pathing detection',
          Moderation: 'Uses Amazon Rekognition moderation detection',
          Text: 'Uses Amazon Rekognition text detection to extract texts from images and videos',
          Customlabel: 'Uses Amazon Rekognition Custom Labels to detect objects',
          Framebased: 'Opt in to use Amazon Rekognition Image APIs',
          Transcribe: 'Uses Amazon Transcribe to convert speech to text from audio file or track',
          Entity: 'Uses Amazon Comprehend to extract entities such as locations, dates, and quantities from the transcription',
          Keyphrase: 'Uses Amazon Comprehend to extract key phrases from the transcription',
          Sentiment: 'Uses Amazon Comprehend to analyze sentiments of the phrases from the transcription',
          Topic: 'Uses Amazon Comprehend to analyze topics of the phrases from the transcription',
          Document: 'Uses Amazon Textract to extract form, key-value pairs, and texts from documents',
          SetAsDefault: 'Save settings as default on your local browser',
          RestoreOriginal: 'Restore settings to the originals',
          ApplyToAllUsers: 'Store settings globally and apply to all users',
          ToggleAll: 'Show all datapoints for all labels in the graph. Rendering all datapoints can affect performance. Recommend to use the \'search\' feature and select label that you are interested in.',
          ToggleTextOverlay: 'Display labels on screen while playing video. Rendering large number of labels can affect video playback performance. Recommend to disable text overlay when you have over 200 labels.',
          ImageProperty: 'This feature analyzes the dominate foreground and background color, brightness, and contrast. It requires Framed Based feature enabled.',
          Scene: 'Enable Scene detection',
          SceneEnhanceWithTranscript: 'Leveraging transcript result to enhance the scene detection',
          SceneEnhanceWithLLM: 'Using Amazon Bedrock with Anthropic Claude V3 Sonnet to generate scene description, taxonomies, brands and logos from the scene level.',
          MinFrameSimilarity: 'Minimum similarity score of frames to be considered in a same scene',
          MaxTimeDistance: 'Proximity range (in minutes) where the detected similar frames should reside in order to be considered a same scene. Larger the number; fewer the scenes. Default to 3 minutes.',
          AdBreak: 'Enable Ad Break detection',
          AdBreakInterval: 'Define how often to evalute an ad break',
          AdBreakOffset: 'Define the search windows (+/-offset) of each interval in minute unit',
          AdBreakWeight: 'The value affects how the weight (priority) of an ad break is calculated',
          AutoFaceIndexer: 'Auto Face Indexer actively indexes unrecognized faces to a face collection. This feature requires Frame Based and Face Match detections',
          MinFaceValue: 'Faces identified with the value lower than the minimum value is ignored',
          MaxPoseThreshold: 'Faces identified with the pose value higher than the threshold is ignored',
          MinCelebConfidence: 'Celebrity identified with a confidnce score higher than the minimum value is ignored. To index all identified celebrities, set the value to 100',
          OccludedFaceFiltering: 'Detect and filter occluded faces from being indexed to the face collection. Default is enabled. (It uses Amazon Rekognition DetectFaces API to identify occluded faces.)',
          ZeroshotLabel: 'This feature uses open source Zero-Shot Image Classification and Zero-Shot Object Detection models to identify custom labels. It requires Framed Based feature enabled.',
          Shoppable: 'This feature uses open source Zero-Shot Object Detection and Zero-Shot Image Classification models to identify Apparel items in the content. It requires Framed Based feature. Recommend to enable Shot Segment feature as well.',
          Toxicity: 'Enable Amazon Transcribe Toxicity Detection feature',
          AnalyseConversation: 'Using Amazon Bedrock with Anthropic Claude V3 Sonnet to analyse the transcript to provide contextual, logical changes of the conversations.',
          /* upload */
          RemoveFromList: 'Remove file from the list?',
          UploadOnly: 'File will be uploaded but won\'t be analyzed',
          /* preview */
          ViewOnAWSConsole: 'view on console',
          ViewJobOnAWSConsole: 'View job on AWS Console',
          DownloadFile: 'download file',
          DeveloperWarning: 'To remove \'For development purposes only\' message, go to \'Settings\' page, enter your Google Map API Key, and refresh the page.',
          Confidence: 'Confidence',
          DeleteImage: 'Delete image',
          SelectMultipleItems: 'Select multiple items',
          PreviewMedia: 'Preview media',
          RefreshStats: 'Refresh stats',
          /* face collection */
          RemoveFaceFromCollection: 'Remove face from collection',
          RemoveFaceCollection: 'Delete the entire face collection!',
          ImportFaceCollection: 'Import the face collection and let Auto Face Indexer manage the collection',
          UploadIndexFaces: 'Upload and index faces to this face collection',
          FaceTaggingTool: 'Run the face tagging wizard to name the unknown faces',
          /* snapshot */
          IndexFace: 'Enter a name of the cropped face and select a face collection to store the face',
          /* user management */
          RemoveUserFromCognito: 'Remove user from user directory',
          GenerateUserToken: 'Generate token for Amazon QuickSight embedded video. User must be in viewer group and verified.',
          RefreshUserTable: 'Fetch users from Amazon Cognito User Pool again',
          SendRequest: 'Send request to foundation model to summary text. This may take up to 30 seconds.',
          Prompt: 'Specify what you want the foundation model to generate; i.e., "Summarize text", "Sentiment of the text", and etc',
          Temperature: 'Control the randonmess of the output. The larger the value; the more randomness of the output.',
          TopK: 'Control the Top "k" tokens should be considered. The smaller the value would likely select the same token for the sentence which implements less randomness of the words being used.',
          TopP: 'Control the probability of picking a token based on the token\'s probability. The smaller the value would likely pick a token with the highest probability.',
          MaxLength: 'Maximum tokens (length) of the generated output. The larger the value; the longer it takes to inference which may also lead to timeout issue. Recommended to choose between 40 to 60.',
          BlackFramePixelThreshold: 'The lower the threshold; the more strict on the black level. Default value is 0.2.',
          BlackFrameCoveragePercentage: 'The higher the coverage %; the more stricted on the noise (non true black) level. Default value is 99.',
          EnableTechnicalCue: 'Enable Technical Cue detection on Amazon Rekognition Segment API to identify BlackFrames, ColorBars, Opening and End Credits. Default is enabled.',
          InputCropX: 'Crop X amount of pixels horizontally. The X value applies to both left and right of the width of the video.',
          InputCropY: 'Crop Y amount of pixels vertically. The Y value applies to both top and bottom of the height of the video.',
          InputCropKeepAR: 'Maintain the video aspect ratio after applying the cropping filter.',
          // face tagging
          EditName: 'Click to edit name',
          SaveChanges: 'Save changes',
          Cancel: 'Cancel changes',
          PlaySegments: 'Play segments',
          ShowOriginalImage: 'Show original image',
          NoImage: 'No image',
        },
        Buttons: {
          Back: 'Back',
          Next: 'Next',
          Cancel: 'Cancel',
          Close: 'Close',
          Done: 'Done',
          Completed: 'Completed',
          QuickUpload: 'Quick upload',
          Startover: 'Start over',
          StartNow: 'Start now',
          StartUpload: 'Start upload',
          Uploading: 'Uploading',
          StartIndex: 'Start indexing',
          Processing: 'Processing',
          Remove: 'Remove',
          BrowseFiles: 'Browse files',
          SetAsDefault: 'Save as default',
          RestoreOriginal: 'Restore original settings',
          ApplyToAllUsers: 'Apply settings to all users',
          DownloadSummary: 'Download summary',
          ClosePreview: 'Close preview window',
          DownloadEDL: 'Download EDL Package',
          Refresh: 'Refresh',
          CreateNewCollection: 'Create new collection',
          RemoveFaceCollection: 'Delete collection',
          ImportFaceCollection: 'Import collection',
          UploadIndexFaces: 'Upload face images',
          IndexFace: 'Index face',
          CleanupDatastore: 'Clean up data store',
          ReAnalyzeContent: 'Re-run AI/ML analysis',
          AddEmail: 'Add email',
          ConfirmAndAddUsers: 'Confirm and add users',
          LoadMore: 'Load more...',
          SendRequest: 'Send request',
          FaceTaggingTool: 'Start face tagging',
          ApplyChangesAndDone: 'Apply changes and done',
          Select: 'Select',
        },
        Statuses: {
          NotStarted: 'Not started',
          Queuing: 'Queuing',
          Waiting: 'Waiting',
          Processing: 'Processing',
          Completed: 'Completed',
          Error: 'Error',
          Total: 'Total',
        },
        Alerts: {
          Oops: 'Oops...',
          Warning: 'Warning',
          Confirmed: 'Confirmed',
          /* sign in */
          PwdConformance: `${FIELD_PWD} doesn't conform with the requirements. Please make sure the ${FIELD_PWD} is at least 8 characters, 1 uppercase, 1 lowercase, 1 numeric, and 1 special character.`,
          UsernameConformance: 'Username don\'t conform with the requirements. Please make sure the username only contains alphanumeric and/or \'.\', \'_\', \'%\', \'+\', \'-\' characters',
          SignInProblem: 'Problem to sign in. Please try again.',
          MismatchPwds: `${FIELD_PWD} doesn't match. Please re-enter the ${FIELD_PWD}`,
          PwdConfirmed: `Your new ${FIELD_PWD} has been set. Please re-sign in to the portal.`,
          SessionExpired: 'Session expired. Please sign in again.',
          /* upload sub-tab */
          NoValidFile: 'No valid file has been imported.',
          /* file component */
          FileTypeNotSupported: 'File type is not supported',
          FileCannotImported: 'A few files cannot be imported.',
          /* attribute component */
          InvalidGroupName: 'Invalid group name. <strong>Group Name</strong> can contain alphnumeric, dash, or underscore characters and must be less than 128 characters.',
          InvalidKeyValue: 'Invalid key or value. <strong>Key</strong> can contain alphnumeric, dash, or underscore characters and must be less than 128 characters. <strong>Value</strong> can contain alphanumeric, dash, underscore, comma, period, or percent sign characters and must be less than 255 characters',
          MaxNumOfAttrs: 'You can add at most 20 attributes.',
          CreateUuidError: 'fail to create an unique uuid...',
          ComputeChecksumError: 'fail to compute MD5 checksum...',
          UploadS3Error: 'fail to upload file to S3 bucket...',
          StartWorkflowError: 'fail to start ingest workflow...',
          /* face collection */
          InvalidFaceCollectionName: 'Face Collection name can only contain alphnumeric, period, dash, and underscore characters and be less than 255 characters',
          ImportFaceCollectionFailed: 'Failed to import <code>{{FACECOLLECTION}}</code> collection.<br>{{ERROR}}',
          /* snapshot */
          InvalidIndexedName: 'Name can only contain alphnumeric, space, period, dash, and underscore characters and be less than 255 characters',
          InvalidFaceCollectionSelection: 'Make sure to select a face collection. If you don`t have any face collection, navigate to <strong>FaceCollection Tab</strong> to create one.',
          ConfirmFaceIndexed: '<strong>{{NAME}}</strong> has successfully added to <strong>{{FACECOLLECTION}}</strong> collection!',
          /* ReAnalyze */
          ReAnalzyeFailed: 'Fail to re-run AI/ML analysis process for <strong>{{BASENAME}}</strong> media.',
          ReAnalyzeSubmitted: 'Re-runing the AI/ML analysis process for <strong>{{BASENAME}}</strong> media.',
          /* Permission */
          DeleteMediaNotAllowed: 'You don\'t have permission to delete the media.',
          InvalidEmailAddress: 'Invalid email address',
          NoNewUsers: 'No user to add',
          FailAddingUsers: 'Problem adding the following users: {{USERS}}',
          /* search */
          InvalidSearchTerm: 'Search query should only contain letters, numbers, punctunations, currencies, and space characters, <code>[\\p{L}\\p{P}\\p{N}\\p{Sc}\\s]+</code>',
          FailUpdatingFaceTags: 'Failed to update face information to the dynamodb table.',
          // adbreak
          NoAdBreakDetected: 'Unable to find any suitable ad break',
          // shoppable
          NoShoppableProduct: 'Unable to find any shoppable products with this video',
          // bedrock
          BedrockServiceUnavailable: 'Amazon Bedrock service unavailable in this region',
          BedrockModelUnavailable: 'The selected foundation model unavailable in this region',
          BedrockAccessRequired: 'Access denied. Please request access to the model in Amazon Bedrock console',
        },
      },
    };
  }
}
